#!/usr/bin/env python3
"""
æ™ºèƒ½å¯¹è¯æœºå™¨äººç³»ç»Ÿ - å¢žå¼ºç‰ˆä¸»ç¨‹åº
é›†æˆå¼ºåŒ–å­¦ä¹ ã€ç”¨æˆ·ç”»åƒã€æ™ºèƒ½å†³ç­–ç­‰åŠŸèƒ½
"""

import os
import sys
import argparse
import yaml
import logging
import numpy as np
from pathlib import Path
import signal
import time
import threading
from typing import Dict, Any
import gradio as gr

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

try:
    from chatbot_system import ChatBot, create_gradio_interface
    from intelligent_agent_training import IntelligentChatBot, UserProfileManager
except ImportError:
    print("âš ï¸ ä½¿ç”¨å†…è”æ¨¡å—...")
    exec(open("chatbot_system.py").read())
    exec(open("intelligent_agent_training.py").read())

class EnhancedChatBotSystem:
    """å¢žå¼ºç‰ˆèŠå¤©æœºå™¨äººç³»ç»Ÿ"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–åŸºç¡€èŠå¤©æœºå™¨äºº
        self.base_chatbot = None
        self.intelligent_bot = None
        
        # ç³»ç»ŸçŠ¶æ€
        self.is_training_mode = config.get('training', {}).get('enabled', False)
        self.model_save_dir = config.get('training', {}).get('save_dir', 'models/trained')
        
        # è®­ç»ƒçº¿ç¨‹
        self.training_thread = None
        self.training_active = False
    
    def initialize(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        try:
            # åˆå§‹åŒ–åŸºç¡€èŠå¤©æœºå™¨äºº
            self.logger.info("åˆå§‹åŒ–åŸºç¡€èŠå¤©æœºå™¨äºº...")
            self.base_chatbot = ChatBot(
                model_name=self.config['model']['chat_model'],
                device=self.config['model']['device'],
                load_in_4bit=self.config['model'].get('load_in_4bit', False),
                embedding_model=self.config['model']['embedding_model'],
                local_files_only=True
            )
            
            # åˆå§‹åŒ–æ™ºèƒ½èŠå¤©æœºå™¨äºº
            self.logger.info("åˆå§‹åŒ–æ™ºèƒ½Agent...")
            self.intelligent_bot = IntelligentChatBot(self.base_chatbot, self.config)
            
            # å°è¯•åŠ è½½å·²è®­ç»ƒçš„æ¨¡åž‹
            if os.path.exists(self.model_save_dir):
                self.intelligent_bot.load_models(self.model_save_dir)
            
            # å¦‚æžœå¯ç”¨è®­ç»ƒæ¨¡å¼ï¼Œå¯åŠ¨åŽå°è®­ç»ƒ
            if self.is_training_mode:
                self.start_training_thread()
            
            self.logger.info("ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            self.logger.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def start_training_thread(self):
        """å¯åŠ¨è®­ç»ƒçº¿ç¨‹"""
        if not self.training_active:
            self.training_active = True
            self.training_thread = threading.Thread(
                target=self._continuous_training,
                daemon=True
            )
            self.training_thread.start()
            self.logger.info("åŽå°è®­ç»ƒçº¿ç¨‹å·²å¯åŠ¨")
    
    def stop_training_thread(self):
        """åœæ­¢è®­ç»ƒçº¿ç¨‹"""
        self.training_active = False
        if self.training_thread and self.training_thread.is_alive():
            self.training_thread.join(timeout=5)
        self.logger.info("åŽå°è®­ç»ƒçº¿ç¨‹å·²åœæ­¢")
    
    def _continuous_training(self):
        """æŒç»­è®­ç»ƒå¾ªçŽ¯"""
        training_interval = self.config.get('training', {}).get('interval', 300)  # 5åˆ†é’Ÿ
        save_interval = self.config.get('training', {}).get('save_interval', 3600)  # 1å°æ—¶
        
        last_save_time = time.time()
        
        while self.training_active:
            try:
                # æ‰§è¡Œè®­ç»ƒæ­¥éª¤
                if self.intelligent_bot and hasattr(self.intelligent_bot.rl_agent, 'train'):
                    self.intelligent_bot.rl_agent.train(batch_size=16)
                
                # å®šæœŸä¿å­˜æ¨¡åž‹
                current_time = time.time()
                if current_time - last_save_time > save_interval:
                    self.save_models()
                    last_save_time = current_time
                
                time.sleep(training_interval)
                
            except Exception as e:
                self.logger.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºçŽ°é”™è¯¯: {e}")
                time.sleep(60)  # å‡ºé”™åŽç­‰å¾…1åˆ†é’Ÿå†ç»§ç»­
    
    def save_models(self):
        """ä¿å­˜æ¨¡åž‹"""
        try:
            if self.intelligent_bot:
                self.intelligent_bot.save_models(self.model_save_dir)
                self.logger.info("æ¨¡åž‹ä¿å­˜æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"æ¨¡åž‹ä¿å­˜å¤±è´¥: {e}")
    
    def chat_with_intelligence(self, message: str, user_id: str = "default", 
                             session_id: str = None, history: list = None) -> tuple:
        """æ™ºèƒ½å¯¹è¯æŽ¥å£"""
        try:
            if not self.intelligent_bot:
                # å›žé€€åˆ°åŸºç¡€èŠå¤©æœºå™¨äºº
                response = self.base_chatbot.chat(message, user_id)
                return response, history + [[message, response]] if history else [[message, response]]
            
            # ä½¿ç”¨æ™ºèƒ½æœºå™¨äººè¿›è¡Œå¯¹è¯
            result = self.intelligent_bot.chat(user_id, message, session_id)
            response = result["response"]
            
            # æ›´æ–°åŽ†å²è®°å½•
            new_history = history + [[message, response]] if history else [[message, response]]
            
            # è®°å½•å¯¹è¯ç»Ÿè®¡ä¿¡æ¯
            self._log_conversation_stats(result)
            
            return response, new_history
            
        except Exception as e:
            self.logger.error(f"å¯¹è¯å¤„ç†å¤±è´¥: {e}")
            fallback_response = "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ï¼Œè¯·ç¨åŽå†è¯•ã€‚"
            new_history = history + [[message, fallback_response]] if history else [[message, fallback_response]]
            return fallback_response, new_history
    
    def provide_user_feedback(self, context_id: str, satisfaction_score: float):
        """ç”¨æˆ·åé¦ˆæŽ¥å£"""
        try:
            if self.intelligent_bot:
                self.intelligent_bot.provide_feedback(context_id, satisfaction_score)
                self.logger.info(f"ç”¨æˆ·åé¦ˆå·²è®°å½•: {context_id}, æ»¡æ„åº¦: {satisfaction_score}")
        except Exception as e:
            self.logger.error(f"åé¦ˆå¤„ç†å¤±è´¥: {e}")
    
    def _log_conversation_stats(self, result: Dict[str, Any]):
        """è®°å½•å¯¹è¯ç»Ÿè®¡ä¿¡æ¯"""
        self.logger.debug(f"å¯¹è¯ç»Ÿè®¡ - æ„å›¾: {result.get('intent')}, "
                         f"ç½®ä¿¡åº¦: {result.get('confidence'):.2f}, "
                         f"è¡ŒåŠ¨: {result.get('action')}")

def create_enhanced_gradio_interface(system: EnhancedChatBotSystem):
    """åˆ›å»ºå¢žå¼ºç‰ˆGradioç•Œé¢"""
    
    def chat_interface(message, history, user_id, system_type):
        """èŠå¤©ç•Œé¢å¤„ç†å‡½æ•°"""
        if not message.strip():
            return "", history
        
        # ç”Ÿæˆä¼šè¯ID
        session_id = f"{user_id}_{int(time.time())}"
        
        response, new_history = system.chat_with_intelligence(
            message, user_id, session_id, history
        )
        
        return "", new_history
    
    def feedback_interface(rating, context_info):
        """åé¦ˆç•Œé¢å¤„ç†å‡½æ•°"""
        if context_info and rating:
            try:
                # è§£æžä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆç®€åŒ–å¤„ç†ï¼‰
                parts = context_info.split('_')
                if len(parts) >= 2:
                    context_id = context_info
                    system.provide_user_feedback(context_id, float(rating))
                    return "âœ… åé¦ˆå·²æäº¤ï¼Œè°¢è°¢æ‚¨çš„è¯„ä»·ï¼"
            except Exception as e:
                return f"âŒ åé¦ˆæäº¤å¤±è´¥: {e}"
        return "è¯·æä¾›æœ‰æ•ˆçš„è¯„åˆ†"
    
    def get_user_stats(user_id):
        """èŽ·å–ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯"""
        try:
            if system.intelligent_bot:
                profile = system.intelligent_bot.user_manager.get_user_profile(user_id)
                stats = f"""
                ðŸ“Š ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯:
                - æ€»å¯¹è¯æ¬¡æ•°: {profile.get('total_conversations', 0)}
                - äº¤äº’é£Žæ ¼: {profile.get('interaction_style', 'æœªçŸ¥')}
                - å¹³å‡æ»¡æ„åº¦: {np.mean(profile.get('satisfaction_history', [3]))::.2f}/5.0
                - å¸¸è§æ„å›¾: {', '.join(profile.get('common_intents', [])[:3])}
                """
                return stats
        except Exception as e:
            return f"èŽ·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}"
        return "æš‚æ— ç»Ÿè®¡ä¿¡æ¯"
    
    # åˆ›å»ºGradioç•Œé¢
    with gr.Blocks(title="æ™ºèƒ½å¯¹è¯æœºå™¨äººç³»ç»Ÿ (AIå¢žå¼ºç‰ˆ)", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ðŸ¤– æ™ºèƒ½å¯¹è¯æœºå™¨äººç³»ç»Ÿ (AIå¢žå¼ºç‰ˆ)")
        gr.Markdown("é›†æˆäº†å¼ºåŒ–å­¦ä¹ ã€ç”¨æˆ·ç”»åƒã€æ™ºèƒ½å†³ç­–çš„å¯¹è¯ç³»ç»Ÿ")
        
        with gr.Row():
            with gr.Column(scale=3):
                # ä¸»å¯¹è¯åŒºåŸŸ
                chatbot = gr.Chatbot(
                    label="å¯¹è¯çª—å£",
                    height=500,
                    show_copy_button=True
                )
                
                with gr.Row():
                    msg_input = gr.Textbox(
                        label="è¾“å…¥æ¶ˆæ¯",
                        placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...",
                        scale=4
                    )
                    send_btn = gr.Button("å‘é€", variant="primary", scale=1)
                
                with gr.Row():
                    clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯", variant="secondary")
                    user_id_input = gr.Textbox(
                        label="ç”¨æˆ·ID",
                        value="default_user",
                        scale=2
                    )
                    system_type = gr.Dropdown(
                        choices=list(system.config.get('system_types', {}).keys()),
                        value="default",
                        label="ç³»ç»Ÿç±»åž‹",
                        scale=2
                    )
            
            with gr.Column(scale=1):
                # ä¾§è¾¹æ åŠŸèƒ½
                gr.Markdown("### ðŸŽ¯ æ™ºèƒ½åŠŸèƒ½")
                
                # ç”¨æˆ·åé¦ˆ
                with gr.Group():
                    gr.Markdown("#### ðŸ“ ç”¨æˆ·åé¦ˆ")
                    feedback_rating = gr.Slider(
                        minimum=1, maximum=5, value=3, step=1,
                        label="æ»¡æ„åº¦è¯„åˆ†"
                    )
                    context_input = gr.Textbox(
                        label="å¯¹è¯ID",
                        placeholder="ä»Žç³»ç»Ÿæ—¥å¿—èŽ·å–...",
                        visible=False
                    )
                    feedback_btn = gr.Button("æäº¤åé¦ˆ", variant="secondary")
                    feedback_output = gr.Textbox(label="åé¦ˆç»“æžœ", interactive=False)
                
                # ç”¨æˆ·ç»Ÿè®¡
                with gr.Group():
                    gr.Markdown("#### ðŸ“Š ç”¨æˆ·ç»Ÿè®¡")
                    stats_btn = gr.Button("æŸ¥çœ‹ç»Ÿè®¡", variant="secondary")
                    stats_output = gr.Markdown("ç‚¹å‡»æŸ¥çœ‹ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯")
                
                # ç³»ç»ŸçŠ¶æ€
                with gr.Group():
                    gr.Markdown("#### âš™ï¸ ç³»ç»ŸçŠ¶æ€")
                    if system.is_training_mode:
                        gr.Markdown("ðŸŸ¢ è®­ç»ƒæ¨¡å¼ï¼šå¼€å¯")
                    else:
                        gr.Markdown("ðŸ”´ è®­ç»ƒæ¨¡å¼ï¼šå…³é—­")
                    
                    save_model_btn = gr.Button("ä¿å­˜æ¨¡åž‹", variant="secondary")
                    save_output = gr.Textbox(label="ä¿å­˜ç»“æžœ", interactive=False)
        
        # äº‹ä»¶ç»‘å®š
        msg_input.submit(
            chat_interface,
            inputs=[msg_input, chatbot, user_id_input, system_type],
            outputs=[msg_input, chatbot]
        )
        
        send_btn.click(
            chat_interface,
            inputs=[msg_input, chatbot, user_id_input, system_type],
            outputs=[msg_input, chatbot]
        )
        
        clear_btn.click(
            lambda: ([], ""),
            outputs=[chatbot, msg_input]
        )
        
        feedback_btn.click(
            feedback_interface,
            inputs=[feedback_rating, context_input],
            outputs=[feedback_output]
        )
        
        stats_btn.click(
            get_user_stats,
            inputs=[user_id_input],
            outputs=[stats_output]
        )
        
        save_model_btn.click(
            lambda: (system.save_models(), "âœ… æ¨¡åž‹å·²ä¿å­˜")[1],
            outputs=[save_output]
        )
        
        # æ·»åŠ ä½¿ç”¨è¯´æ˜Ž
        gr.Markdown("""
        ### ðŸ“– ä½¿ç”¨è¯´æ˜Ž
        
        **æ™ºèƒ½åŠŸèƒ½ç‰¹æ€§ï¼š**
        - ðŸ§  **å¼ºåŒ–å­¦ä¹ **: æ ¹æ®ç”¨æˆ·åé¦ˆä¸æ–­æ”¹è¿›å›žç­”è´¨é‡
        - ðŸ‘¤ **ç”¨æˆ·ç”»åƒ**: è®°ä½ç”¨æˆ·åå¥½ï¼Œæä¾›ä¸ªæ€§åŒ–æœåŠ¡  
        - ðŸŽ¯ **æ„å›¾è¯†åˆ«**: æ™ºèƒ½ç†è§£ç”¨æˆ·çœŸå®žéœ€æ±‚
        - ðŸ’­ **ä¸Šä¸‹æ–‡è®°å¿†**: å‚è€ƒåŽ†å²å¯¹è¯æä¾›æ›´å¥½çš„å›žç­”
        - ðŸ“Š **æ™ºèƒ½å†³ç­–**: æ ¹æ®æƒ…å†µé€‰æ‹©æœ€ä½³å›žç­”ç­–ç•¥
        
        **æ“ä½œæç¤ºï¼š**
        1. è¾“å…¥ç”¨æˆ·IDä»¥èŽ·å¾—ä¸ªæ€§åŒ–ä½“éªŒ
        2. é€‰æ‹©åˆé€‚çš„ç³»ç»Ÿç±»åž‹ï¼ˆé€šç”¨åŠ©æ‰‹/å®¢æœåŠ©æ‰‹ç­‰ï¼‰
        3. å¯¹å›žç­”è´¨é‡è¿›è¡Œè¯„åˆ†å¸®åŠ©ç³»ç»Ÿå­¦ä¹ 
        4. æŸ¥çœ‹ä¸ªäººç»Ÿè®¡äº†è§£ä½¿ç”¨æƒ…å†µ
        """)
    
    return demo

def load_enhanced_config(config_path: str) -> Dict[Any, Any]:
    """åŠ è½½å¢žå¼ºç‰ˆé…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        print(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {config_path}")
        return config
    except FileNotFoundError:
        print(f"âŒ é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")
        print("ä½¿ç”¨é»˜è®¤é…ç½®...")
        return get_enhanced_default_config()
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        print("ä½¿ç”¨é»˜è®¤é…ç½®...")
        return get_enhanced_default_config()

def get_enhanced_default_config() -> Dict[Any, Any]:
    """èŽ·å–å¢žå¼ºç‰ˆé»˜è®¤é…ç½®"""
    return {
        'model': {
            'chat_model': '/root/conversation/local_dialoGPT',
            'embedding_model': '/root/conversation/local_model',
            'load_in_4bit': False,
            'device': 'auto',
            'generation': {
                'max_new_tokens': 512,
                'temperature': 0.7,
                'top_p': 0.9,
                'do_sample': True
            }
        },
        'knowledge': {
            'chunk_size': 500,
            'chunk_overlap': 50,
            'similarity_threshold': 0.3,
            'max_retrieved_docs': 3
        },
        'dialogue': {
            'max_history': 10,
            'session_timeout': 3600
        },
        'web': {
            'title': 'æ™ºèƒ½å¯¹è¯æœºå™¨äººç³»ç»Ÿ (AIå¢žå¼ºç‰ˆ)',
            'host': '0.0.0.0',
            'port': 7860,
            'share': False,
            'theme': 'soft'
        },
        'logging': {
            'level': 'INFO',
            'file': 'logs/chatbot.log'
        },
        'system_types': {
            'default': {'name': 'é€šç”¨åŠ©æ‰‹'},
            'customer_service': {'name': 'å®¢æœåŠ©æ‰‹'},
            'campus_qa': {'name': 'æ ¡å›­é—®ç­”'},
            'intelligent': {'name': 'AIæ™ºèƒ½åŠ©æ‰‹'}
        },
        'training': {
            'enabled': True,
            'interval': 300,  # è®­ç»ƒé—´éš”ï¼ˆç§’ï¼‰
            'save_interval': 3600,  # æ¨¡åž‹ä¿å­˜é—´éš”ï¼ˆç§’ï¼‰
            'save_dir': 'models/trained',
            'batch_size': 32,
            'learning_rate': 0.001
        },
        'intelligence': {
            'use_reinforcement_learning': True,
            'use_user_profiling': True,
            'use_contextual_memory': True,
            'memory_size': 1000,
            'similarity_threshold': 0.7
        }
    }

def setup_enhanced_logging(config: Dict[Any, Any]):
    """è®¾ç½®å¢žå¼ºç‰ˆæ—¥å¿—"""
    log_config = config.get('logging', {})
    log_level = getattr(logging, log_config.get('level', 'INFO').upper())
    log_file = log_config.get('file', 'logs/chatbot.log')
    
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    Path(log_file).parent.mkdir(exist_ok=True)
    
    # é…ç½®æ—¥å¿—æ ¼å¼
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'
    )
    
    # æ–‡ä»¶å¤„ç†å™¨ - æ™®é€šæ—¥å¿—
    file_handler = logging.FileHandler(log_file)
    file_handler.setFormatter(formatter)
    
    # æ–‡ä»¶å¤„ç†å™¨ - è®­ç»ƒæ—¥å¿—
    training_handler = logging.FileHandler(log_file.replace('.log', '_training.log'))
    training_handler.setFormatter(formatter)
    training_handler.addFilter(lambda record: 'training' in record.getMessage().lower())
    
    # æŽ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    
    # æ ¹æ—¥å¿—å™¨
    root_logger = logging.getLogger()
    root_logger.setLevel(log_level)
    root_logger.addHandler(file_handler)
    root_logger.addHandler(training_handler)
    root_logger.addHandler(console_handler)
    
    print(f"âœ… å¢žå¼ºç‰ˆæ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œæ—¥å¿—æ–‡ä»¶: {log_file}")

def signal_handler(signum, frame, system):
    """å¢žå¼ºç‰ˆä¿¡å·å¤„ç†å™¨"""
    print(f"\nðŸ›‘ æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...")
    
    # åœæ­¢è®­ç»ƒçº¿ç¨‹
    if system:
        system.stop_training_thread()
        system.save_models()
    
    print("ðŸ‘‹ ç³»ç»Ÿå·²å®‰å…¨å…³é—­")
    sys.exit(0)

def main():
    """å¢žå¼ºç‰ˆä¸»å‡½æ•°"""
    import numpy as np  # æ·»åŠ numpyå¯¼å…¥
    
    # è§£æžå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="æ™ºèƒ½å¯¹è¯æœºå™¨äººç³»ç»Ÿ (AIå¢žå¼ºç‰ˆ)")
    parser.add_argument("--config", default="/root/conversation/config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--host", help="WebæœåŠ¡å™¨ä¸»æœºåœ°å€")
    parser.add_argument("--port", type=int, help="WebæœåŠ¡å™¨ç«¯å£")
    parser.add_argument("--device", choices=["cuda", "cpu"], help="è®¾å¤‡ç±»åž‹")
    parser.add_argument("--model", help="èŠå¤©æ¨¡åž‹è·¯å¾„")
    parser.add_argument("--load-in-4bit", action="store_true", help="ä½¿ç”¨4bité‡åŒ–")
    parser.add_argument("--knowledge-dir", default="data/knowledge", help="çŸ¥è¯†åº“ç›®å½•")
    parser.add_argument("--create-sample", action="store_true", help="åˆ›å»ºç¤ºä¾‹çŸ¥è¯†æ–‡ä»¶")
    parser.add_argument("--enable-training", action="store_true", help="å¯ç”¨è®­ç»ƒæ¨¡å¼")
    parser.add_argument("--disable-training", action="store_true", help="ç¦ç”¨è®­ç»ƒæ¨¡å¼")
    parser.add_argument("--debug", action="store_true", help="è°ƒè¯•æ¨¡å¼")
    
    args = parser.parse_args()
    
    print("ðŸš€ å¯åŠ¨æ™ºèƒ½å¯¹è¯æœºå™¨äººç³»ç»Ÿ (AIå¢žå¼ºç‰ˆ)")
    print("=" * 60)
    
    # åŠ è½½é…ç½®
    config = load_enhanced_config(args.config)
    
    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
    if args.host:
        config['web']['host'] = args.host
    if args.port:
        config['web']['port'] = args.port
    if args.device:
        config['model']['device'] = args.device
    if args.model:
        config['model']['chat_model'] = args.model
    if args.load_in_4bit:
        config['model']['load_in_4bit'] = True
    if args.enable_training:
        config['training']['enabled'] = True
    if args.disable_training:
        config['training']['enabled'] = False
    if args.debug:
        config['logging']['level'] = 'DEBUG'
    
    # è®¾ç½®æ—¥å¿—
    setup_enhanced_logging(config)
    logger = logging.getLogger(__name__)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    system = None
    
    try:
        # åˆ›å»ºç¤ºä¾‹çŸ¥è¯†æ–‡ä»¶
        if args.create_sample:
            create_sample_knowledge()
        
        # åˆå§‹åŒ–å¢žå¼ºç‰ˆç³»ç»Ÿ
        print("ðŸ§  åˆå§‹åŒ–AIå¢žå¼ºç³»ç»Ÿ...")
        system = EnhancedChatBotSystem(config)
        
        if not system.initialize():
            print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
            return 1
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, lambda s, f: signal_handler(s, f, system))
        signal.signal(signal.SIGTERM, lambda s, f: signal_handler(s, f, system))
        
        # åŠ è½½çŸ¥è¯†åº“
        print("ðŸ“š åŠ è½½çŸ¥è¯†åº“...")
        if hasattr(system.base_chatbot, 'knowledge_base'):
            load_knowledge_from_directory(system.base_chatbot, args.knowledge_dir)
        
        # åˆ›å»ºå¢žå¼ºç‰ˆWebç•Œé¢
        print("ðŸŒ åˆ›å»ºAIå¢žå¼ºWebç•Œé¢...")
        demo = create_enhanced_gradio_interface(system)
        
        # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
        web_config = config['web']
        host = web_config.get('host', '0.0.0.0')
        port = web_config.get('port', 7860)
        
        print("=" * 60)
        print("âœ… AIå¢žå¼ºç³»ç»Ÿå¯åŠ¨æˆåŠŸ!")
        print(f"ðŸŒ Webç•Œé¢: http://{host}:{port}")
        if host == '0.0.0.0':
            print(f"ðŸ”— æœ¬åœ°è®¿é—®: http://localhost:{port}")
        print(f"ðŸ“Š æ¨¡åž‹: {config['model']['chat_model']}")
        print(f"ðŸ§  æ™ºèƒ½åŠŸèƒ½: {'âœ…' if config.get('intelligence', {}).get('use_reinforcement_learning') else 'âŒ'} å¼ºåŒ–å­¦ä¹ ")
        print(f"ðŸ‘¤ ç”¨æˆ·ç”»åƒ: {'âœ…' if config.get('intelligence', {}).get('use_user_profiling') else 'âŒ'} å·²å¯ç”¨")  
        print(f"ðŸ’­ ä¸Šä¸‹æ–‡è®°å¿†: {'âœ…' if config.get('intelligence', {}).get('use_contextual_memory') else 'âŒ'} å·²å¯ç”¨")
        print(f"ðŸŽ¯ è®­ç»ƒæ¨¡å¼: {'âœ… å·²å¯ç”¨' if config.get('training', {}).get('enabled') else 'âŒ å·²ç¦ç”¨'}")
        print("=" * 60)
        
        # å¯åŠ¨WebæœåŠ¡
        logger.info("å¯åŠ¨AIå¢žå¼ºWebæœåŠ¡...")
        demo.launch(
            server_name=host,
            server_port=port,
            share=web_config.get('share', False),
            show_api=False,
            quiet=False
        )
        
    except KeyboardInterrupt:
        print("\nðŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œç³»ç»Ÿå…³é—­")
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
        logger.exception("ç³»ç»Ÿå¯åŠ¨å¼‚å¸¸")
        return 1
    finally:
        # æ¸…ç†èµ„æº
        if system:
            system.stop_training_thread()
            system.save_models()
    
    print("ðŸ‘‹ AIå¢žå¼ºç³»ç»Ÿå·²å…³é—­")
    return 0

# ä»ŽåŽŸmain.pyå¤åˆ¶çš„è¾…åŠ©å‡½æ•°
def load_knowledge_from_directory(chatbot, knowledge_dir: str):
    """ä»Žç›®å½•åŠ è½½çŸ¥è¯†æ–‡ä»¶"""
    knowledge_path = Path(knowledge_dir)
    if not knowledge_path.exists():
        print(f"âš ï¸ çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨: {knowledge_dir}")
        return
    
    loaded_files = 0
    supported_extensions = {'.txt', '.md', '.json'}
    
    for file_path in knowledge_path.rglob('*'):
        if file_path.is_file() and file_path.suffix.lower() in supported_extensions:
            try:
                if hasattr(chatbot, 'add_knowledge_from_file'):
                    chatbot.add_knowledge_from_file(str(file_path))
                    loaded_files += 1
                    print(f"  ðŸ“„ {file_path.name}")
            except Exception as e:
                print(f"  âŒ åŠ è½½å¤±è´¥ {file_path.name}: {e}")
    
    print(f"âœ… ä»Ž {knowledge_dir} åŠ è½½äº† {loaded_files} ä¸ªçŸ¥è¯†æ–‡ä»¶")

def create_sample_knowledge():
    """åˆ›å»ºç¤ºä¾‹çŸ¥è¯†æ–‡ä»¶ï¼ˆå¤ç”¨åŽŸå‡½æ•°ï¼‰"""
    knowledge_dir = Path("data/knowledge")
    knowledge_dir.mkdir(parents=True, exist_ok=True)
    
    sample_files = {
        "ai_enhanced_features.txt": """
AIå¢žå¼ºåŠŸèƒ½è¯´æ˜Žï¼š

å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿï¼š
- æ ¹æ®ç”¨æˆ·åé¦ˆè‡ªåŠ¨ä¼˜åŒ–å›žç­”ç­–ç•¥
- æ”¯æŒå¤šç§å¥–åŠ±æœºåˆ¶å’Œå­¦ä¹ ç®—æ³•
- å®žæ—¶è°ƒæ•´å¯¹è¯é£Žæ ¼å’Œå†…å®¹æ·±åº¦

ç”¨æˆ·ç”»åƒç³»ç»Ÿï¼š  
- è®°å½•ç”¨æˆ·åå¥½å’Œäº¤äº’åŽ†å²
- ä¸ªæ€§åŒ–å›žç­”é£Žæ ¼å’Œå†…å®¹æŽ¨è
- æ™ºèƒ½é¢„æµ‹ç”¨æˆ·éœ€æ±‚

ä¸Šä¸‹æ–‡è®°å¿†ï¼š
- é•¿æœŸè®°ä½ç”¨æˆ·å¯¹è¯åŽ†å²
- è·¨ä¼šè¯ä¿¡æ¯å…³è”å’Œå¼•ç”¨
- æ™ºèƒ½ç›¸ä¼¼å¯¹è¯æ£€ç´¢

æ„å›¾è¯†åˆ«ï¼š
- è‡ªåŠ¨è¯†åˆ«ç”¨æˆ·çœŸå®žæ„å›¾
- æ”¯æŒå¤šå±‚æ¬¡æ„å›¾åˆ†æž
- åŠ¨æ€è°ƒæ•´å›žç­”ç­–ç•¥

è®­ç»ƒæ¨¡å¼ï¼š
- åŽå°æŒç»­å­¦ä¹ ç”¨æˆ·åé¦ˆ
- å®šæœŸä¿å­˜å’Œæ›´æ–°æ¨¡åž‹
- æ”¯æŒå¢žé‡å­¦ä¹ å’Œæ¨¡åž‹ä¼˜åŒ–
        """
    }
    
    # æ·»åŠ åŽŸæœ‰çš„ç¤ºä¾‹æ–‡ä»¶ï¼ˆç®€åŒ–ç‰ˆï¼‰
    sample_files.update({
        "customer_service.txt": "å®¢æœç›¸å…³ä¿¡æ¯...",
        "campus_info.txt": "æ ¡å›­ä¿¡æ¯...", 
        "faq.txt": "å¸¸è§é—®é¢˜..."
    })
    
    created_count = 0
    for filename, content in sample_files.items():
        file_path = knowledge_dir / filename
        if not file_path.exists():
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content.strip())
            created_count += 1
    
    if created_count > 0:
        print(f"âœ… åˆ›å»ºäº† {created_count} ä¸ªç¤ºä¾‹çŸ¥è¯†æ–‡ä»¶")

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
